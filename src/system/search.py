# def semantic_search_with_score(db, query, limit=3):
#     """
#     –í—ã–ø–æ–ª–Ω—è–µ—Ç —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–∏—Å–∫ –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã —Å –∏—Ö –æ—Ü–µ–Ω–∫–∞–º–∏.

#     :param db: –û–±—ä–µ–∫—Ç –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö, –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—â–∏–π similarity_search_with_score.
#     :param query: –°—Ç—Ä–æ–∫–∞ –∑–∞–ø—Ä–æ—Å–∞.
#     :param limit: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –¥–ª—è –≤–æ–∑–≤—Ä–∞—Ç–∞.
#     :return: –ö–æ—Ä—Ç–µ–∂ –∏–∑ –¥–≤—É—Ö —Å–ø–∏—Å–∫–æ–≤: –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –∏ –∏—Ö –æ—Ü–µ–Ω–æ–∫.
#     """
#     # –ó–∞–ø—Ä–∞—à–∏–≤–∞–µ–º –±–æ–ª—å—à–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤, —á—Ç–æ–±—ã –∫–æ–º–ø–µ–Ω—Å–∏—Ä–æ–≤–∞—Ç—å –≤–æ–∑–º–æ–∂–Ω—ã–µ –¥—É–±–ª–∏–∫–∞—Ç—ã
#     over_fetch_limit = limit * 2
#     results = db._collection.similarity_search_with_score(query, k=limit)

#     seen = set()
#     unique_docs = []
#     unique_scores = []

#     for doc, score in results:
#         content = doc.page_content.strip()
#         if content not in seen:
#             seen.add(content)
#             unique_docs.append(content)
#             unique_scores.append(score)
#             if len(unique_docs) >= limit:
#                 break

#     return unique_docs, unique_scores


# #===== Reranker =====#
# # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏ –¥–ª—è —Ä–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏—è
# from transformers import BertTokenizer, BertForSequenceClassification, AutoModelForSequenceClassification

# # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä–∞ –∏ –º–æ–¥–µ–ª–∏ –¥–ª—è —Ä–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏—è
# tokenizer_reranker = BertTokenizer.from_pretrained("nlpaueb/legal-bert-base-uncased")
# model_reranker = BertForSequenceClassification.from_pretrained("nlpaueb/legal-bert-base-uncased").to(device)

# model_reranker.eval()

# def rerank_and_filter(query, documents, top_n=3, threshold=0.3):
#     # –†–µ—Ä–∞–Ω–∫–∏–Ω–≥ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
#     inputs = tokenizer_reranker([query]*len(documents), documents, return_tensors='pt', truncation=True, padding=True)
#     with torch.no_grad():
#         outputs = model_reranker(**inputs)
#     scores = torch.softmax(outputs.logits, dim=1)[:,1].tolist()

#     ranked_docs = sorted(zip(documents, scores), key=lambda x: x[1])

#     # –í—ã–±–æ—Ä –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –Ω–∏–∂–µ –ø–æ—Ä–æ–≥–∞
#     filtered_docs = [doc for doc, score in ranked_docs if score <= threshold]

#     # –ï—Å–ª–∏ –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –º–µ–Ω—å—à–µ top_n, –¥–æ–ø–æ–ª–Ω—è–µ–º –∏—Ö —Ç–æ–ø-N
#     if len(filtered_docs) < top_n:
#         filtered_docs = [doc for doc, score in ranked_docs[:top_n]]

#     rearranged_docs_topn = filtered_docs[:top_n]
#     rearranged_docs = [rearranged_docs_topn[1]] + rearranged_docs_topn[2:2+(top_n-2)] + [rearranged_docs_topn[0]]
#     return rearranged_docs, rearranged_docs_topn

import weaviate.classes as wvc
from weaviate.classes.query import HybridFusion, Rerank

def hybrid_search_with_rerank(collection, query, limit=10, rerank_limit=3, use_parent_docs=True):
    """
    –ì–∏–±—Ä–∏–¥–Ω—ã–π –ø–æ–∏—Å–∫ —Å —Ä–µ—Ä–µ–Ω–∫–∏–Ω–≥–æ–º –∏—Å–ø–æ–ª—å–∑—É—è BAAI/bge-reranker-v2-m3

    :param collection: Weaviate –∫–æ–ª–ª–µ–∫—Ü–∏—è
    :param query: –ü–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å
    :param limit: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –¥–ª—è –ø–µ—Ä–≤–∏—á–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞
    :param rerank_limit: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–ø —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø–æ—Å–ª–µ —Ä–µ—Ä–µ–Ω–∫–∏–Ω–≥–∞
    :param use_parent_docs: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ø–æ–ª–Ω—ã–µ —Ä–æ–¥–∏—Ç–µ–ª—å—Å–∫–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã –≤–º–µ—Å—Ç–æ —á–∞–Ω–∫–æ–≤
    :return: –°–ø–∏—Å–æ–∫ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø–æ—Å–ª–µ —Ä–µ—Ä–µ–Ω–∫–∏–Ω–≥–∞ (—Å —Ä–æ–¥–∏—Ç–µ–ª—å—Å–∫–∏–º–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞–º–∏ –µ—Å–ª–∏ use_parent_docs=True)
    """
    try:
        # STEP 1: –û–±—ã—á–Ω—ã–π –≥–∏–±—Ä–∏–¥–Ω—ã–π –ø–æ–∏—Å–∫ –ë–ï–ó —Ä–µ—Ä–µ–Ω–∫–∏–Ω–≥–∞
        print(f"\n{'='*80}")
        print(f"=== STEP 1: Hybrid Search (WITHOUT reranking) ===")
        print(f"{'='*80}")
        results_before = collection.query.hybrid(
            query=query,
            alpha=0.35,
            query_properties=["text_for_bm25", 'title'],
            fusion_type=HybridFusion.RELATIVE_SCORE,
            return_metadata=wvc.query.MetadataQuery(score=True),
            limit=limit
        )

        print(f"\nFound {len(results_before.objects)} results")

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –î–û —Ä–µ—Ä–µ–Ω–∫–∏–Ω–≥–∞
        before_ranking = []
        original_scores = {}
        for i, obj in enumerate(results_before.objects):
            doc_id = str(obj.uuid)
            score = obj.metadata.score
            title = obj.properties.get('title', 'N/A')

            original_scores[doc_id] = {
                'score': score,
                'position': i + 1,
                'title': title,
                'text': obj.properties.get('original_text', '')
            }
            before_ranking.append({
                'uuid': doc_id,
                'title': title,
                'score': score,
                'position': i + 1
            })

            print(f"{i+1:2d}. Score: {score:.6f} | {title[:70]}")

        # STEP 2: –ì–∏–±—Ä–∏–¥–Ω—ã–π –ø–æ–∏—Å–∫ –° —Ä–µ—Ä–µ–Ω–∫–∏–Ω–≥–æ–º
        print(f"\n{'='*80}")
        print(f"=== STEP 2: Hybrid Search WITH Reranking ===")
        print(f"{'='*80}")
        results_after = collection.query.hybrid(
            query=query,
            alpha=0.35,
            query_properties=["text_for_bm25", 'title'],
            fusion_type=HybridFusion.RELATIVE_SCORE,
            return_metadata=wvc.query.MetadataQuery(score=True),
            limit=limit,
            rerank=Rerank(
                prop="original_text",
                query=query
            )
        )

        print(f"\nFound {len(results_after.objects)} results after reranking")

        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ü–û–°–õ–ï —Ä–µ—Ä–µ–Ω–∫–∏–Ω–≥–∞
        after_ranking = []
        for i, obj in enumerate(results_after.objects):
            doc_id = str(obj.uuid)
            rerank_score = obj.metadata.score
            title = obj.properties.get('title', 'N/A')

            original_data = original_scores.get(doc_id, {})
            original_score = original_data.get('score', 0.0)
            original_position = original_data.get('position', '?')

            position_change = original_position - (i + 1) if isinstance(original_position, int) else 0
            position_indicator = "üî∫" if position_change > 0 else "üîª" if position_change < 0 else "‚û°Ô∏è"

            after_ranking.append({
                'uuid': doc_id,
                'title': title,
                'original_score': original_score,
                'rerank_score': rerank_score,
                'original_position': original_position,
                'new_position': i + 1,
                'position_change': position_change
            })

            print(f"{i+1:2d}. {position_indicator} (was #{original_position}) | Hybrid: {original_score:.6f} ‚Üí Rerank: {rerank_score:.6f} | {title[:50]}")

        # –§–æ—Ä–º–∏—Ä—É–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏–µ–π —Ä–æ–¥–∏—Ç–µ–ª—å—Å–∫–∏—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
        print(f"\n{'='*80}")
        if use_parent_docs:
            print(f"=== STEP 3: Parent Document Retrieval with Deduplication ===")
        else:
            print(f"=== DETAILED TOP {rerank_limit} RESULTS ===")
        print(f"{'='*80}")

        reranked_results = []
        seen_parent_docs = set()  # –î–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Ä–æ–¥–∏—Ç–µ–ª—å—Å–∫–∏—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤

        # –ò—Ç–µ—Ä–∏—Ä—É–µ–º—Å—è –ø–æ –≤—Å–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º –ø–æ—Å–ª–µ —Ä–µ—Ä–µ–Ω–∫–∏–Ω–≥–∞
        for i, obj in enumerate(results_after.objects):
            # –ü—Ä–µ–∫—Ä–∞—â–∞–µ–º –µ—Å–ª–∏ –Ω–∞–±—Ä–∞–ª–∏ –Ω—É–∂–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
            if len(reranked_results) >= rerank_limit:
                break

            doc_id = str(obj.uuid)
            original_data = original_scores.get(doc_id, {})
            parent_doc_id = obj.properties.get('parent_doc_id', doc_id)

            # –ï—Å–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ä–æ–¥–∏—Ç–µ–ª—å—Å–∫–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã –∏ —ç—Ç–æ—Ç parent —É–∂–µ –±—ã–ª - –ø—Ä–æ–ø—É—Å–∫–∞–µ–º
            if use_parent_docs and parent_doc_id in seen_parent_docs:
                print(f"   ‚è≠Ô∏è  Skipping duplicate parent doc (chunk from same document)")
                continue

            # –û—Ç–º–µ—á–∞–µ–º parent –¥–æ–∫—É–º–µ–Ω—Ç –∫–∞–∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω—ã–π
            if use_parent_docs:
                seen_parent_docs.add(parent_doc_id)

            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–∞–∫–æ–π —Ç–µ–∫—Å—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å
            if use_parent_docs:
                text_to_use = obj.properties.get('parent_doc_text', obj.properties.get('original_text', ''))
                text_type = "parent_document"
            else:
                text_to_use = obj.properties.get('original_text', '')
                text_type = "chunk"

            result = {
                'title': obj.properties.get('title', 'N/A'),
                'source': obj.properties.get('source', 'N/A'),
                'text': text_to_use,
                'chunk_text': obj.properties.get('original_text', ''),  # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π —á–∞–Ω–∫ –¥–ª—è —Å–ø—Ä–∞–≤–∫–∏
                'url': obj.properties.get('url', 'N/A'),
                'timestamp': obj.properties.get('timestamp', 0),
                'hybrid_score': original_data.get('score', 0.0),
                'rerank_score': obj.metadata.score,
                'original_position': original_data.get('position', '?'),
                'new_position': i + 1,
                'chunk_index': obj.properties.get('chunk_index', 0),
                'parent_doc_id': parent_doc_id,
                'text_type': text_type
            }
            reranked_results.append(result)

            position_change = result['original_position'] - result['new_position'] if isinstance(result['original_position'], int) else 0
            score_change = result['rerank_score'] - result['hybrid_score']

            print(f"\nüìÑ Result #{len(reranked_results)}")
            print(f"   Title: {result['title']}")
            print(f"   Type: {'üîπ Full Parent Document' if use_parent_docs else 'üìÑ Chunk'}")
            if use_parent_docs:
                print(f"   Retrieved from chunk #{result['chunk_index']}")
            print(f"   Position: #{result['original_position']} ‚Üí #{result['new_position']} (Œî {position_change:+d} places)")
            print(f"   Hybrid Score:  {result['hybrid_score']:.6f}")
            print(f"   Rerank Score:  {result['rerank_score']:.6f}")
            print(f"   Score Change:  {score_change:+.6f}")
            print(f"   Source: {result['source']}")
            if use_parent_docs:
                print(f"   Chunk preview: {result['chunk_text'][:120]}...")
                print(f"   Full doc length: {len(result['text'])} chars")
            else:
                print(f"   Text: {result['text'][:120]}...")

        print(f"\n‚úÖ Final results: {len(reranked_results)} unique {'parent documents' if use_parent_docs else 'chunks'}")
        if use_parent_docs and len(seen_parent_docs) < len(results_after.objects[:rerank_limit]):
            print(f"   ‚ÑπÔ∏è  Skipped {len(results_after.objects[:rerank_limit]) - len(seen_parent_docs)} duplicate parent documents")

        return reranked_results

    except Exception as e:
        print(f"Search with rerank failed: {e}")
        import traceback
        traceback.print_exc()
        return []

# –ü—Ä–∏–º–µ—Ä –ø–æ–∏—Å–∫–∞ —Å GPU –≤–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏–µ–π (—Å—Ç–∞—Ä–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏)
def hybrid_search_test(collection, query):
    try:
        # –ì–∏–±—Ä–∏–¥–Ω—ã–π –ø–æ–∏—Å–∫ (Weaviate –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –≤–µ–∫—Ç–æ—Ä–∏–∑–∏—Ä—É–µ—Ç –∑–∞–ø—Ä–æ—Å —Å –ø–æ–º–æ—â—å—é GPU)
        results = collection.query.hybrid(
            query=query,
            alpha=0.35,  # 0.5 = —Ä–∞–≤–Ω—ã–π –≤–µ—Å –≤–µ–∫—Ç–æ—Ä–Ω–æ–º—É –∏ BM25
            query_properties=["text_for_bm25", 'title'],
            fusion_type=HybridFusion.RELATIVE_SCORE,
            return_metadata=wvc.query.MetadataQuery(score=True),
            limit=10
        )

        print(f"Found {len(results.objects)} results for query: '{query}'")
        for i, obj in enumerate(results.objects):
            print(f"\n{i+1}. Title: {obj.properties.get('title', 'N/A')}")
            print(f"   Source: {obj.properties.get('source', 'N/A')}")
            print(f"   Text: {obj.properties.get('original_text', '')[:200]}...")
            print(f"   Score: {obj.metadata.score}")

    except Exception as e:
        print(f"Search test failed: {e}")
