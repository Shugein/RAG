# src/services/events/ceg_realtime_service.py
"""
Real-time CEG Service - —Ä–µ–∞–∫—Ç–∏–≤–Ω—ã–π —Å–µ—Ä–≤–∏—Å –¥–ª—è –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è CEG –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏

–≠—Ç–æ—Ç —Å–µ—Ä–≤–∏—Å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏:
1. –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –Ω–æ–≤—ã–µ –Ω–æ–≤–æ—Å—Ç–∏ –ø—Ä–∏ –∏—Ö –∑–∞–≥—Ä—É–∑–∫–µ
2. –ò–∑–≤–ª–µ–∫–∞–µ—Ç —Å–æ–±—ã—Ç–∏—è —á–µ—Ä–µ–∑ EventExtractor
3. –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –ø—Ä–∏—á–∏–Ω–Ω–æ—Å—Ç—å —Å –ø–æ–º–æ—â—å—é CMNLN
4. –í—ã–ø–æ–ª–Ω—è–µ—Ç Event Study –¥–ª—è —Ä—ã–Ω–æ—á–Ω–æ–≥–æ –≤–ª–∏—è–Ω–∏—è
5. –û–±–Ω–æ–≤–ª—è–µ—Ç –≥—Ä–∞—Ñ Neo4j
6. –†–µ—Ç—Ä–æ—Å–ø–µ–∫—Ç–∏–≤–Ω–æ –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –≤–ª–∏—è–Ω–∏–µ –Ω–∞ –ø—Ä–µ–¥—ã–¥—É—â–∏–µ –Ω–æ–≤–æ—Å—Ç–∏
"""

import logging
from typing import List, Dict, Any, Optional
from datetime import datetime, timedelta
from uuid import uuid4

from sqlalchemy import select
from sqlalchemy.ext.asyncio import AsyncSession

from src.core.models import News, Event, EventImportance, TriggeredWatch, EventPrediction
from src.graph_models import GraphService, EventNode, CausesRelation, ImpactsRelation
from src.services.events.event_extractor import EventExtractor
from src.services.events.cmnln_engine import CMLNEngine
from src.services.events.importance_calculator import ImportanceScoreCalculator
from src.services.events.watchers import WatchersSystem, WatchLevel
from src.services.events.event_prediction import EventPredictionEngine
from src.services.moex.moex_prices import MOEXPriceService, EventStudyAnalyzer

logger = logging.getLogger(__name__)


class CEGRealtimeService:
    """
    –†–µ–∞–∫—Ç–∏–≤–Ω—ã–π —Å–µ—Ä–≤–∏—Å CEG - –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –Ω–æ–≤–æ—Å—Ç–∏ –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏
    """

    def __init__(
        self,
        session: AsyncSession,
        graph_service: GraphService,
        lookback_window: int = 30,  # –î–Ω–µ–π –¥–ª—è —Ä–µ—Ç—Ä–æ—Å–ø–µ–∫—Ç–∏–≤–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
        enable_watchers: bool = True,  # –í–∫–ª—é—á–∏—Ç—å —Å–∏—Å—Ç–µ–º—É –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞
        enable_predictions: bool = True  # –í–∫–ª—é—á–∏—Ç—å —Å–∏—Å—Ç–µ–º—É –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π
    ):
        """
        Args:
            session: SQLAlchemy async session
            graph_service: GraphService –¥–ª—è Neo4j
            lookback_window: –û–∫–Ω–æ –¥–ª—è –ø–æ–∏—Å–∫–∞ —Å–≤—è–∑–∞–Ω–Ω—ã—Ö —Å–æ–±—ã—Ç–∏–π (–¥–Ω–µ–π –Ω–∞–∑–∞–¥)
            enable_watchers: –í–∫–ª—é—á–∏—Ç—å —Å–∏—Å—Ç–µ–º—É watcher'–æ–≤ (L0/L1/L2)
            enable_predictions: –í–∫–ª—é—á–∏—Ç—å —Å–∏—Å—Ç–µ–º—É –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π —Å–æ–±—ã—Ç–∏–π
        """
        self.session = session
        self.graph = graph_service
        self.lookback_window = lookback_window
        self.enable_watchers = enable_watchers
        self.enable_predictions = enable_predictions

        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
        self.event_extractor = EventExtractor()
        self.cmnln = CMLNEngine(graph_service=graph_service, session=session)
        self.moex = MOEXPriceService()
        self.event_study = EventStudyAnalyzer(self.moex)
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –Ω–æ–≤—ã—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
        self.importance_calculator = ImportanceScoreCalculator(session, graph_service)
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Watchers —Å–∏—Å—Ç–µ–º—ã
        if self.enable_watchers:
            self.watchers_system = WatchersSystem(graph_service, self.importance_calculator)
            # –î–æ–±–∞–≤–ª—è–µ–º –æ–±—Ä–∞–±–æ—Ç—á–∏–∫ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–π
            self.watchers_system.add_notification_handler(self._handle_watcher_notification)
        else:
            self.watchers_system = None
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–∏—Å—Ç–µ–º—ã –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π
        if self.enable_predictions:
            self.prediction_engine = EventPredictionEngine(session, graph_service)
        else:
            self.prediction_engine = None

        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        self.stats = {
            "news_processed": 0,
            "events_created": 0,
            "causal_links_created": 0,
            "impacts_calculated": 0,
            "retroactive_updates": 0,
            "importance_calculated": 0,
            "watchers_triggered": 0,
            "predictions_generated": 0,
            "predictions_fulfilled": 0
        }

    async def close(self):
        """–ó–∞–∫—Ä—ã—Ç–∏–µ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π"""
        await self.moex.close()

    async def process_news(
        self,
        news: News,
        ai_extracted: Any
    ) -> Dict[str, Any]:
        """
        –û–±—Ä–∞–±–æ—Ç–∞—Ç—å –Ω–æ–≤—É—é –Ω–æ–≤–æ—Å—Ç—å –∏ –æ–±–Ω–æ–≤–∏—Ç—å CEG

        Args:
            news: –û–±—ä–µ–∫—Ç News
            ai_extracted: –†–µ–∑—É–ª—å—Ç–∞—Ç AI extraction

        Returns:
            {
                'events': List[Event],
                'causal_links': List[tuple],
                'impacts': List[dict],
                'retroactive_links': int
            }
        """
        logger.info(f"Processing news {news.id} for CEG: {news.title[:60]}")

        result = {
            "events": [],
            "causal_links": [],
            "impacts": [],
            "retroactive_links": 0
        }

        try:
            # 1. –ò–∑–≤–ª–µ–∫–∞–µ–º —Å–æ–±—ã—Ç–∏—è –∏–∑ –Ω–æ–≤–æ—Å—Ç–∏
            events = self.event_extractor.extract_events_from_news(news, ai_extracted)

            if not events:
                logger.debug(f"No events extracted from news {news.id}")
                return result

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å–æ–±—ã—Ç–∏—è –≤ –ë–î
            for event in events:
                self.session.add(event)
            await self.session.flush()

            result["events"] = events
            self.stats["events_created"] += len(events)

            # 2. –°–æ–∑–¥–∞–µ–º —É–∑–ª—ã —Å–æ–±—ã—Ç–∏–π –≤ Neo4j
            for event in events:
                event_node = EventNode(
                    id=str(event.id),
                    title=event.title,
                    ts=event.ts,
                    type=event.event_type,
                    attrs=event.attrs,
                    is_anchor=event.is_anchor,
                    confidence=event.confidence
                )
                await self.graph.create_event_ceg(event_node)

            # 3. –ò—â–µ–º –ø—Ä–∏—á–∏–Ω–Ω–æ-—Å–ª–µ–¥—Å—Ç–≤–µ–Ω–Ω—ã–µ —Å–≤—è–∑–∏ —Å –ø—Ä–µ–¥—ã–¥—É—â–∏–º–∏ —Å–æ–±—ã—Ç–∏—è–º–∏
            causal_links = await self._find_causal_links(events)
            result["causal_links"] = causal_links
            self.stats["causal_links_created"] += len(causal_links)

            # 4. –í—ã–ø–æ–ª–Ω—è–µ–º Event Study –¥–ª—è —Ä—ã–Ω–æ—á–Ω–æ–≥–æ –≤–ª–∏—è–Ω–∏—è
            impacts = await self._calculate_impacts(events)
            result["impacts"] = impacts
            self.stats["impacts_calculated"] += len(impacts)

            # 5. –†–µ—Ç—Ä–æ—Å–ø–µ–∫—Ç–∏–≤–Ω—ã–π –∞–Ω–∞–ª–∏–∑: –æ–±–Ω–æ–≤–ª—è–µ–º —Å–≤—è–∑–∏ –¥–ª—è –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö —Å–æ–±—ã—Ç–∏–π
            retroactive_count = await self._retroactive_analysis(events)
            result["retroactive_links"] = retroactive_count
            self.stats["retroactive_updates"] += retroactive_count

            # 6. –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –≤–∞–∂–Ω–æ—Å—Ç—å —Å–æ–±—ã—Ç–∏–π (Importance Score)
            importance_data = {}
            for event in events:
                importance_calc = await self.importance_calculator.calculate_importance_score(event)
                importance_data[str(event.id)] = importance_calc
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –ë–î
                importance_record = EventImportance(
                    event_id=event.id,
                    importance_score=importance_calc['importance_score'],
                    novelty=importance_calc['novelty'],
                    burst=importance_calc['burst'],
                    credibility=importance_calc['credibility'],
                    breadth=importance_calc['breadth'],
                    price_impact=importance_calc['price_impact'],
                    components_details=importance_calc.get('components_details', {}),
                    calculation_timestamp=importance_calc['calculation_timestamp'],
                    weights_version="1.0"
                )
                self.session.add(importance_record)
            
            await self.session.flush()
            
            # 7. –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–±—ã—Ç–∏–π watcher'–∞–º–∏ (–µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω—ã)
            watched_results = {}
            if self.watchers_system:
                for event in events:
                    watch_results = await self.watchers_system.check_event(event)
                    watched_results[str(event.id)] = watch_results
                    
                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å—Ä–∞–±–æ—Ç–∞–≤—à–∏–µ watcher'—ã –≤ –ë–î
                    if watch_results['summary']['total_triggers'] > 0:
                        for level_result in watch_results['level_results'].values():
                            for triggered_watch_data in level_result.get('triggered_watches', []):
                                triggered_watch = TriggeredWatch(
                                    rule_id=triggered_watch_data['rule_id'],
                                    rule_name=triggered_watch_data['rule_name'],
                                    watch_level=triggered_watch_data['trigger_time'][:2],  # L0, L1, L2
                                    event_id=event.id,
                                    trigger_time=datetime.fromisoformat(triggered_watch_data['trigger_time']),
                                    auto_expire_at=datetime.fromisoformat(triggered_watch_data['trigger_time']) + timedelta(hours=168),
                                    context=triggered_watch_data['context']
                                )
                                self.session.add(triggered_watch)
                                
                                # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –¥–ª—è L2 watcher'–æ–≤
                                if self.prediction_engine and triggered_watch.watch_level == 'L2':
                                    try:
                                        predictions = await self.prediction_engine.generate_l2_predictions(
                                            triggered_watch, 
                                            prediction_types=['follow_up_events', 'market_reactions']
                                        )
                                        self.stats["predictions_generated"] += len(predictions)
                                        logger.debug(f"Generated {len(predictions)} predictions for L2 watch {triggered_watch.rule_id}")
                                    except Exception as e:
                                        logger.error(f"Error generating predictions for watch {triggered_watch.id}: {e}")
            
            await self.session.flush()

            # 8. –ö–æ–º–º–∏—Ç–∏–º –≤—Å–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è –≤ –ë–î
            await self.session.commit()

            self.stats["news_processed"] += 1
            self.stats["importance_calculated"] += len(importance_data)
            if self.watchers_system:
                self.stats["watchers_triggered"] = sum(
                    result['summary']['total_triggers'] 
                    for result in watched_results.values()
                )

            predictions_count = self.stats.get("predictions_generated", 0)
            logger.info(
                f"CEG update with importance, watchers & predictions complete for news {news.id}: "
                f"{len(events)} events, {len(causal_links)} links, "
                f"{len(impacts)} impacts, {retroactive_count} retroactive updates, "
                f"{len(importance_data)} importance scores, "
                f"{sum(len(wr['summary']['levels_triggered']) for wr in watched_results.values()) if watched_results else 0} watcher triggers, "
                f"{predictions_count} predictions generated"
            )

        except Exception as e:
            logger.error(f"Error processing news {news.id} for CEG: {e}", exc_info=True)
            await self.session.rollback()
            raise

        return result

    async def _find_causal_links(self, new_events: List[Event]) -> List[tuple]:
        """
        –ù–∞–π—Ç–∏ –ø—Ä–∏—á–∏–Ω–Ω–æ-—Å–ª–µ–¥—Å—Ç–≤–µ–Ω–Ω—ã–µ —Å–≤—è–∑–∏ –¥–ª—è –Ω–æ–≤—ã—Ö —Å–æ–±—ã—Ç–∏–π

        –ò—â–µ—Ç —Å–≤—è–∑–∏ –∫–∞–∫:
        - old_event -> new_event (–ø—Ä–æ—à–ª—ã–µ —Å–æ–±—ã—Ç–∏—è –≤—ã–∑–≤–∞–ª–∏ –Ω–æ–≤–æ–µ)
        - new_event1 -> new_event2 (–≤ —Ä–∞–º–∫–∞—Ö –æ–¥–Ω–æ–π –Ω–æ–≤–æ—Å—Ç–∏)
        """
        causal_links = []

        # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å–æ–±—ã—Ç–∏—è –∑–∞ lookback_window
        lookback_date = datetime.utcnow() - timedelta(days=self.lookback_window)

        stmt = select(Event).where(
            Event.ts >= lookback_date,
            Event.id.not_in([e.id for e in new_events])
        ).order_by(Event.ts.desc()).limit(200)

        result = await self.session.execute(stmt)
        past_events = result.scalars().all()

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø—Ä–∏—á–∏–Ω–Ω–æ—Å—Ç—å –º–µ–∂–¥—É –ø—Ä–æ—à–ª—ã–º–∏ –∏ –Ω–æ–≤—ã–º–∏ —Å–æ–±—ã—Ç–∏—è–º–∏
        for past_event in past_events:
            for new_event in new_events:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—É—é –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å
                if past_event.ts >= new_event.ts:
                    continue

                # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø—Ä–∏—á–∏–Ω–Ω–æ—Å—Ç—å —á–µ—Ä–µ–∑ CMNLN
                relation = await self.cmnln.detect_causality(
                    cause_event=past_event,
                    effect_event=new_event,
                    news_text=""  # TODO: –º–æ–∂–µ–º –ø–µ—Ä–µ–¥–∞—Ç—å —Ç–µ–∫—Å—Ç –Ω–æ–≤–æ—Å—Ç–∏
                )

                if relation:
                    # –î–æ–±–∞–≤–ª—è–µ–º conf_market –µ—Å–ª–∏ –µ—Å—Ç—å —Ç–∏–∫–µ—Ä—ã
                    if new_event.attrs.get("tickers"):
                        ticker = new_event.attrs["tickers"][0]
                        conf_market = await self.event_study.calculate_market_confidence(
                            ticker, new_event.ts
                        )
                        relation.conf_market = conf_market

                        # –ü–µ—Ä–µ—Å—á–∏—Ç—ã–≤–∞–µ–º total confidence
                        relation.conf_total = self.cmnln._calculate_total_confidence(
                            relation.conf_prior,
                            relation.conf_text,
                            relation.conf_market
                        )

                    # –°–æ–∑–¥–∞–µ–º —Å–≤—è–∑—å –≤ Neo4j
                    await self.graph.link_events_causes(
                        cause_id=str(past_event.id),
                        effect_id=str(new_event.id),
                        causes=relation
                    )

                    causal_links.append((past_event, new_event, relation))

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–≤—è–∑–∏ –º–µ–∂–¥—É –Ω–æ–≤—ã–º–∏ —Å–æ–±—ã—Ç–∏—è–º–∏
        for i, event1 in enumerate(new_events):
            for event2 in new_events[i+1:]:
                if event1.ts >= event2.ts:
                    continue

                relation = await self.cmnln.detect_causality(
                    cause_event=event1,
                    effect_event=event2,
                    news_text=""
                )

                if relation:
                    await self.graph.link_events_causes(
                        cause_id=str(event1.id),
                        effect_id=str(event2.id),
                        causes=relation
                    )

                    causal_links.append((event1, event2, relation))

        return causal_links

    async def _calculate_impacts(self, events: List[Event]) -> List[Dict[str, Any]]:
        """
        –†–∞—Å—Å—á–∏—Ç–∞—Ç—å —Ä—ã–Ω–æ—á–Ω–æ–µ –≤–ª–∏—è–Ω–∏–µ —Å–æ–±—ã—Ç–∏–π —á–µ—Ä–µ–∑ Event Study
        """
        impacts = []

        for event in events:
            tickers = event.attrs.get("tickers", [])

            if not tickers:
                continue

            for ticker in tickers[:3]:  # –ú–∞–∫—Å–∏–º—É–º 3 —Ç–∏–∫–µ—Ä–∞ –Ω–∞ —Å–æ–±—ã—Ç–∏–µ
                try:
                    impact = await self.event_study.analyze_event_impact(
                        event_id=str(event.id),
                        secid=ticker,
                        event_date=event.ts
                    )

                    if impact and impact.get("is_significant"):
                        # –°–æ–∑–¥–∞–µ–º —É–∑–µ–ª –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞ –≤ Neo4j
                        await self.graph.create_instrument_node(
                            instrument_id=f"MOEX:{ticker}",
                            symbol=ticker,
                            instrument_type="equity",
                            exchange="MOEX",
                            currency="RUB"
                        )

                        # –°–æ–∑–¥–∞–µ–º —Å–≤—è–∑—å IMPACTS
                        impacts_rel = ImpactsRelation(
                            price_impact=impact["ar"],
                            volume_impact=impact["volume_spike"],
                            sentiment=1.0 if impact["ar"] > 0 else -1.0 if impact["ar"] < 0 else 0.0,
                            window="1d"
                        )

                        await self.graph.link_event_impacts_instrument(
                            event_id=str(event.id),
                            instrument_id=f"MOEX:{ticker}",
                            impacts=impacts_rel
                        )

                        impacts.append(impact)

                except Exception as e:
                    logger.warning(f"Error calculating impact for {ticker}: {e}")

        return impacts

    async def _retroactive_analysis(self, new_events: List[Event]) -> int:
        """
        –†–µ—Ç—Ä–æ—Å–ø–µ–∫—Ç–∏–≤–Ω—ã–π –∞–Ω–∞–ª–∏–∑: –Ω–æ–≤—ã–µ —Å–æ–±—ã—Ç–∏—è –º–æ–≥—É—Ç –±—ã—Ç—å –ø—Ä–∏—á–∏–Ω–∞–º–∏/—Å–ª–µ–¥—Å—Ç–≤–∏—è–º–∏
        –¥–ª—è —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö —Å–æ–±—ã—Ç–∏–π

        –ù–∞–ø—Ä–∏–º–µ—Ä:
        - –î–µ–Ω—å 1: –°–æ–±—ã—Ç–∏–µ "earnings" –¥–ª—è SBER
        - –î–µ–Ω—å 3: –ù–æ–≤–æ–µ —Å–æ–±—ã—Ç–∏–µ "sanctions" (–º–æ–∂–µ—Ç –æ–±—ä—è—Å–Ω–∏—Ç—å –ø—Ä–µ–¥—ã–¥—É—â–µ–µ –ø–∞–¥–µ–Ω–∏–µ)

        –≠—Ç–æ—Ç –º–µ—Ç–æ–¥ –Ω–∞—Ö–æ–¥–∏—Ç —Ç–∞–∫–∏–µ —Å–≤—è–∑–∏ –∏ –æ–±–Ω–æ–≤–ª—è–µ—Ç –≥—Ä–∞—Ñ
        """
        retroactive_links = 0

        # –ò—â–µ–º —Å–æ–±—ã—Ç–∏—è, –∫–æ—Ç–æ—Ä—ã–µ –ø—Ä–æ–∏–∑–æ—à–ª–∏ –ü–û–°–õ–ï –Ω–æ–≤—ã—Ö —Å–æ–±—ã—Ç–∏–π
        # (–Ω–æ–≤–æ–µ —Å–æ–±—ã—Ç–∏–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –ø—Ä–∏—á–∏–Ω–æ–π —Å—Ç–∞—Ä–æ–≥–æ)
        for new_event in new_events:
            future_date_start = new_event.ts + timedelta(hours=1)
            future_date_end = new_event.ts + timedelta(days=self.lookback_window)

            stmt = select(Event).where(
                Event.ts >= future_date_start,
                Event.ts <= future_date_end,
                Event.id != new_event.id
            ).limit(100)

            result = await self.session.execute(stmt)
            future_events = result.scalars().all()

            for future_event in future_events:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø—Ä–∏—á–∏–Ω–Ω–æ—Å—Ç—å new_event -> future_event
                relation = await self.cmnln.detect_causality(
                    cause_event=new_event,
                    effect_event=future_event,
                    news_text=""
                )

                if relation:
                    # –î–æ–±–∞–≤–ª—è–µ–º conf_market
                    if future_event.attrs.get("tickers"):
                        ticker = future_event.attrs["tickers"][0]
                        conf_market = await self.event_study.calculate_market_confidence(
                            ticker, future_event.ts
                        )
                        relation.conf_market = conf_market
                        relation.conf_total = self.cmnln._calculate_total_confidence(
                            relation.conf_prior,
                            relation.conf_text,
                            relation.conf_market
                        )

                    # –°–æ–∑–¥–∞–µ–º/–æ–±–Ω–æ–≤–ª—è–µ–º —Å–≤—è–∑—å –≤ Neo4j
                    await self.graph.link_events_causes(
                        cause_id=str(new_event.id),
                        effect_id=str(future_event.id),
                        causes=relation
                    )

                    retroactive_links += 1

        return retroactive_links

    async def batch_process_recent_news(self, days: int = 7) -> Dict[str, int]:
        """
        –ü–∞–∫–µ—Ç–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –Ω–µ–¥–∞–≤–Ω–∏—Ö –Ω–æ–≤–æ—Å—Ç–µ–π –¥–ª—è –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è CEG

        –ü–æ–ª–µ–∑–Ω–æ –¥–ª—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –≥—Ä–∞—Ñ–∞ –∏–ª–∏ –ø–µ—Ä–µ–æ–±—Ä–∞–±–æ—Ç–∫–∏

        Args:
            days: –°–∫–æ–ª—å–∫–æ –¥–Ω–µ–π –Ω–∞–∑–∞–¥ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å
        """
        from_date = datetime.utcnow() - timedelta(days=days)

        stmt = select(News).where(
            News.published_at >= from_date
        ).order_by(News.published_at.asc())

        result = await self.session.execute(stmt)
        news_list = result.scalars().all()

        logger.info(f"Batch processing {len(news_list)} news items for CEG")

        processed = 0
        errors = 0

        for news in news_list:
            try:
                # TODO: –ù—É–∂–Ω–æ –∑–∞–≥—Ä—É–∑–∏—Ç—å AI extracted entities –∏–∑ –ë–î –∏–ª–∏ –ø–µ—Ä–µ—Å–æ–∑–¥–∞—Ç—å
                # –î–ª—è –ø—Ä–æ—Å—Ç–æ—Ç—ã –ø—Ä–æ–ø—É—Å—Ç–∏–º –Ω–æ–≤–æ—Å—Ç–∏ –±–µ–∑ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã—Ö entities
                # –í —Ä–µ–∞–ª—å–Ω–æ–π —Å–∏—Å—Ç–µ–º–µ –Ω—É–∂–Ω–æ –∑–∞–ø—É—Å—Ç–∏—Ç—å AI extraction –∑–∞–Ω–æ–≤–æ

                # await self.process_news(news, ai_extracted)
                processed += 1

            except Exception as e:
                logger.error(f"Error processing news {news.id}: {e}")
                errors += 1

        return {
            "total": len(news_list),
            "processed": processed,
            "errors": errors,
            "events_created": self.stats["events_created"],
            "causal_links": self.stats["causal_links_created"],
            "impacts": self.stats["impacts_calculated"]
        }

    def get_stats(self) -> Dict[str, int]:
        """–ü–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É —Ä–∞–±–æ—Ç—ã —Å–µ—Ä–≤–∏—Å–∞"""
        stats = self.stats.copy()
        
        # –î–æ–±–∞–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É watcher'–æ–≤ –µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω—ã
        if self.watchers_system:
            watcher_stats = self.watchers_system.get_statistics()
            stats.update(watcher_stats['system_statistics'])
            stats['total_active_watches'] = watcher_stats['total_active_watches']
        
        return stats
    
    async def _handle_watcher_notification(self, notification: Dict[str, Any]):
        """
        –û–±—Ä–∞–±–æ—Ç—á–∏–∫ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–π –æ—Ç watcher'–æ–≤
        
        Args:
            notification: –î–∞–Ω–Ω—ã–µ —É–≤–µ–¥–º–æ–∂–µ–Ω–∏—è:
                {
                    'watch_id': str,
                    'watch_name': str,
                    'level': str,
                    'trigger_event_id': str,
                    'trigger_time': str,
                    'alerts': List[str],
                    'context': dict,
                    'priority': str
                }
        """
        logger.info(
            f"üì® WATCHER ALERT [{notification['priority'].upper()}] "
            f"{notification['watch_name']} ({notification['level']}) "
            f"triggered by event {notification['trigger_event_id']}"
        )
        
        # –ó–¥–µ—Å—å –º–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –æ—Ç–ø—Ä–∞–≤–∫—É —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–π –≤:
        # - Slack/Discord
        # - Email
        # - SMS
        # - Webhook'–∏
        # - –°–∏—Å—Ç–µ–º–∞ –∞–ª–µ—Ä—Ç–æ–≤
        
        # –ü—Ä–∏–º–µ—Ä –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è –¥–µ—Ç–∞–ª—å–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏
        logger.info(f"Notification details: {notification}")
        
        # –ü—Ä–∏–º–µ—Ä –æ—Ç–ø—Ä–∞–≤–∫–∏ –≤ Telegram (–µ—Å–ª–∏ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–æ)
        # await self._send_telegram_alert(notification)
        
        # –ü—Ä–∏–º–µ—Ä –æ—Ç–ø—Ä–∞–≤–∫–∏ –≤ webhook (–µ—Å–ª–∏ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–æ)
        # await self._send_webhook_alert(notification)
    
    async def get_watcher_statistics(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É watcher'–æ–≤"""
        if not self.watchers_system:
            return {"error": "Watchers system not enabled"}
        
        return self.watchers_system.get_statistics()
    
    async def cleanup_expired_watchers(self):
        """–û—á–∏—Å—Ç–∏—Ç—å –∏—Å—Ç–µ–∫—à–∏–µ watcher'—ã"""
        if self.watchers_system:
            await self.watchers_system.cleanup_expired_watches()
    
    async def check_and_update_predictions(self):
        """–ü—Ä–æ–≤–µ—Ä–∏—Ç—å –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π –∏ –æ–±–Ω–æ–≤–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É"""
        if not self.prediction_engine:
            return {"error": "Prediction engine not enabled"}
        
        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π
            fulfilled_predictions = await self.prediction_engine.check_prediction_fulfillment()
            
            # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
            if fulfilled_predictions:
                self.stats["predictions_fulfilled"] += len(fulfilled_predictions)
            
            # –û–±–Ω–æ–≤–ª—è–µ–º —Ç–æ—á–Ω–æ—Å—Ç—å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π
            accuracy_stats = await self.prediction_engine.update_predictions_accuracy()
            
            logger.info(f"Checked predictions: {len(fulfilled_predictions)} fulfilled, "
                       f"accuracy: {accuracy_stats.get('overall_accuracy', 0):.3f}")
            
            return {
                "fulfilled_count": len(fulfilled_predictions),
                "accuracy_stats": accuracy_stats
            }
            
        except Exception as e:
            logger.error(f"Error checking predictions: {e}", exc_info=True)
            return {"error": str(e)}
    
    def get_prediction_statistics(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É —Å–∏—Å—Ç–µ–º—ã –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π"""
        if not self.prediction_engine:
            return {"error": "Prediction engine not enabled"}
        
        return self.prediction_engine.get_statistics()
