#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import undetected_chromedriver as uc
import time
import json
import csv
from datetime import datetime
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import TimeoutException, NoSuchElementException
import re

class ExtendedNewsParser:
    def __init__(self, headless=False):
        self.driver = None
        self.headless = headless
        self.news_data = []
        
    def create_driver(self):
        try:
            options = uc.ChromeOptions()
            
            if self.headless:
                options.add_argument('--headless')
            
            options.add_argument('--no-first-run')
            options.add_argument('--no-service-autorun')
            options.add_argument('--no-default-browser-check')
            options.add_argument('--disable-default-apps')
            options.add_argument('--disable-popup-blocking')
            options.add_argument('--disable-translate')
            options.add_argument('--disable-background-timer-throttling')
            options.add_argument('--disable-renderer-backgrounding')
            options.add_argument('--disable-backgrounding-occluded-windows')
            options.add_argument('--disable-client-side-phishing-detection')
            options.add_argument('--disable-sync')
            options.add_argument('--disable-features=TranslateUI')
            
            self.driver = uc.Chrome(
                options=options,
                version_main=140
            )
            
            self.driver.execute_script("Object.defineProperty(navigator, 'webdriver', {get: () => undefined})")
            self.driver.execute_script("Object.defineProperty(navigator, 'plugins', {get: () => [1, 2, 3, 4, 5]})")
            self.driver.execute_script("Object.defineProperty(navigator, 'languages', {get: () => ['ru-RU', 'ru']})")
            
            return True
            
        except Exception as e:
            print(f" –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –¥—Ä–∞–π–≤–µ—Ä–∞: {e}")
            return False
    
    def navigate_to_page(self, page_num):
        """–ü–µ—Ä–µ—Ö–æ–¥–∏–º –Ω–∞ —É–∫–∞–∑–∞–Ω–Ω—É—é —Å—Ç—Ä–∞–Ω–∏—Ü—É —á–µ—Ä–µ–∑ –∫–ª–∏–∫ –ø–æ –ø–∞–≥–∏–Ω–∞—Ü–∏–∏"""
        try:
            if page_num == 1:
                self.driver.get("https://www.e-disclosure.ru/vse-novosti")
                time.sleep(3)
                return True
            
            paging_div = self.driver.find_element(By.CSS_SELECTOR, ".paging")
            page_links = paging_div.find_elements(By.CSS_SELECTOR, "a.page")
            
            for link in page_links:
                data_page = link.get_attribute("data-link-page")
                if data_page and int(data_page) == page_num:
                    print(f" –ö–ª–∏–∫–∞–µ–º –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—É {page_num}")
                    self.driver.execute_script("arguments[0].click();", link)
                    time.sleep(3)  # –ñ–¥–µ–º –∑–∞–≥—Ä—É–∑–∫–∏ –ø–æ—Å–ª–µ –∫–ª–∏–∫–∞
                    return True
            
            print(f" –ù–µ –Ω–∞–π–¥–µ–Ω–∞ –∫–Ω–æ–ø–∫–∞ –¥–ª—è —Å—Ç—Ä–∞–Ω–∏—Ü—ã {page_num}")
            return False
            
        except Exception as e:
            print(f" –û—à–∏–±–∫–∞ –Ω–∞–≤–∏–≥–∞—Ü–∏–∏ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—É {page_num}: {e}")
            return False
    
    def parse_news_page(self, page_num=1):
        """–ü–∞—Ä—Å–∏–º —Å—Ç—Ä–∞–Ω–∏—Ü—É –Ω–æ–≤–æ—Å—Ç–µ–π (—Ç–æ–ª—å–∫–æ –±–∞–∑–æ–≤–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è)"""
        try:
            print(f" –ü–∞—Ä—Å–∏–º —Å—Ç—Ä–∞–Ω–∏—Ü—É {page_num}")
            
            if not self.navigate_to_page(page_num):
                return False
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∑–∞—â–∏—Ç—É
            if "servicepipe" in self.driver.page_source.lower():
                print(" ServicePipe –±–ª–æ–∫–∏—Ä—É–µ—Ç")
                return False
                
            # –ò—â–µ–º –Ω–æ–≤–æ—Å—Ç–∏
            try:
                WebDriverWait(self.driver, 10).until(
                    EC.presence_of_element_located((By.ID, "newsList"))
                )
                
                news_container = self.driver.find_element(By.ID, "newsList")
                
                time_elements = news_container.find_elements(By.CSS_SELECTOR, ".time")
                listitem_elements = news_container.find_elements(By.CSS_SELECTOR, ".listitem")
                
                print(f"–ù–∞–π–¥–µ–Ω–æ –¥–∞—Ç: {len(time_elements)}, –Ω–æ–≤–æ—Å—Ç–µ–π: {len(listitem_elements)}")
                
                page_news = []
                for i in range(min(len(time_elements), len(listitem_elements))):
                    try:
                        news_item = self.extract_news_from_elements(time_elements[i], listitem_elements[i])
                        if news_item:
                            page_news.append(news_item)
                    except Exception as e:
                        print(f" –û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –Ω–æ–≤–æ—Å—Ç–∏ {i}: {e}")
                        continue
                
                print(f" –ò–∑–≤–ª–µ—á–µ–Ω–æ –Ω–æ–≤–æ—Å—Ç–µ–π –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ {page_num}: {len(page_news)}")
                self.news_data.extend(page_news)
                return len(page_news) > 0
                
            except TimeoutException:
                print(" –¢–∞–π–º–∞—É—Ç –æ–∂–∏–¥–∞–Ω–∏—è –∫–æ–Ω—Ç–µ–Ω—Ç–∞")
                return False
                
        except Exception as e:
            print(f" –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã {page_num}: {e}")
            return False
    
    def extract_news_from_elements(self, time_element, listitem_element):
        try:
            date_element = time_element.find_element(By.CSS_SELECTOR, ".date")
            date_text = date_element.text.strip()
            
            link_element = listitem_element.find_element(By.CSS_SELECTOR, "a.blacklink")
            news_title = link_element.text.strip()
            news_url = link_element.get_attribute("href")
            
            news_item = {
                'date': date_text,
                'title': news_title,
                'url': news_url,
                'full_url': f"https://www.e-disclosure.ru{news_url}" if news_url.startswith('/') else news_url,
                'content': None,  # –ë—É–¥–µ—Ç –∑–∞–ø–æ–ª–Ω–µ–Ω–æ –ø–æ–∑–∂–µ
                'content_extracted': False,
                'parsed_at': datetime.now().isoformat()
            }
            
            return news_item
            
        except Exception as e:
            print(f" –û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö –∏–∑ —ç–ª–µ–º–µ–Ω—Ç–æ–≤: {e}")
            return None
    
    def extract_news_content(self, news_item):
        try:
            print(f" –ü–æ–ª—É—á–∞–µ–º —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ: {news_item['title'][:50]}...")
            
            self.driver.get(news_item['full_url'])
            time.sleep(2)
            
            content_text = ""
            
            content_selectors = [
                ".news-content",
                ".article-content", 
                ".content",
                ".news-text",
                ".article-text",
                "div[class*='content']",
                "div[class*='text']",
                ".main-content p",
                "article p",
                "main p"
            ]
            
            for selector in content_selectors:
                try:
                    content_elements = self.driver.find_elements(By.CSS_SELECTOR, selector)
                    if content_elements:
                        texts = []
                        for elem in content_elements:
                            text = elem.text.strip()
                            if text and len(text) > 20:  # –ò–≥–Ω–æ—Ä–∏—Ä—É–µ–º —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–µ —Ç–µ–∫—Å—Ç—ã
                                texts.append(text)
                        
                        if texts:
                            content_text = "\n\n".join(texts)
                            print(f" –ù–∞–π–¥–µ–Ω –∫–æ–Ω—Ç–µ–Ω—Ç —á–µ—Ä–µ–∑ —Å–µ–ª–µ–∫—Ç–æ—Ä: {selector}")
                            break
                            
                except Exception as e:
                    continue
            
            if not content_text:
                try:
                    paragraphs = self.driver.find_elements(By.TAG_NAME, "p")
                    texts = []
                    for p in paragraphs:
                        text = p.text.strip()
                        if len(text) > 50:  # –ë–µ—Ä–µ–º —Ç–æ–ª—å–∫–æ —Å–æ–¥–µ—Ä–∂–∞—Ç–µ–ª—å–Ω—ã–µ –ø–∞—Ä–∞–≥—Ä–∞—Ñ—ã
                            texts.append(text)
                    
                    if texts:
                        content_text = "\n\n".join(texts)
                        print(" –ù–∞–π–¥–µ–Ω –∫–æ–Ω—Ç–µ–Ω—Ç —á–µ—Ä–µ–∑ –ø–∞—Ä–∞–≥—Ä–∞—Ñ—ã")
                        
                except Exception as e:
                    print(f" –û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ –ø–∞—Ä–∞–≥—Ä–∞—Ñ–æ–≤: {e}")
            
            news_item['content'] = content_text if content_text else "–°–æ–¥–µ—Ä–∂–∞–Ω–∏–µ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ"
            news_item['content_extracted'] = bool(content_text)
            news_item['content_length'] = len(content_text) if content_text else 0
            
            return True
            
        except Exception as e:
            print(f" –û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Å–æ–¥–µ—Ä–∂–∞–Ω–∏—è: {e}")
            news_item['content'] = f"–û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è: {str(e)}"
            news_item['content_extracted'] = False
            return False
    
    def check_next_page_available(self, target_page):
        try:
            paging_div = self.driver.find_element(By.CSS_SELECTOR, ".paging")
            page_links = paging_div.find_elements(By.CSS_SELECTOR, "a.page")
            
            for link in page_links:
                page_number = link.get_attribute("data-link-page")
                if page_number and int(page_number) == target_page:
                    return True
                    
            for link in page_links:
                img = link.find_elements(By.CSS_SELECTOR, "img[src*='next.png']")
                if img:
                    return True
                    
            return False
            
        except Exception as e:
            print(f" –û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ –ø–∞–≥–∏–Ω–∞—Ü–∏–∏: {e}")
            return False
    
    def parse_all_news_with_content(self, max_pages=5):
        print(f" –ù–∞—á–∏–Ω–∞–µ–º –ø–æ–ª–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥ –Ω–æ–≤–æ—Å—Ç–µ–π (–º–∞–∫—Å. {max_pages} —Å—Ç—Ä–∞–Ω–∏—Ü)")
        
        if not self.create_driver():
            return False
        
        try:
            print("\n –≠–¢–ê–ü 1: –°–±–æ—Ä —Å–ø–∏—Å–∫–∞ –Ω–æ–≤–æ—Å—Ç–µ–π")
            print("-" * 50)
            
            page = 1
            success = self.parse_news_page(page)
            
            if not success:
                print(f" –ù–µ —É–¥–∞–ª–æ—Å—å —Å–ø–∞—Ä—Å–∏—Ç—å –ø–µ—Ä–≤—É—é —Å—Ç—Ä–∞–Ω–∏—Ü—É")
                return False
            
            page = 2
            while page <= max_pages:
                if not self.check_next_page_available(page):
                    print(f" –î–æ—Å—Ç–∏–≥–Ω—É—Ç–∞ –ø–æ—Å–ª–µ–¥–Ω—è—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞: {page-1}")
                    break
                
                success = self.parse_news_page(page)
                
                if not success:
                    print(f" –ù–µ —É–¥–∞–ª–æ—Å—å —Å–ø–∞—Ä—Å–∏—Ç—å —Å—Ç—Ä–∞–Ω–∏—Ü—É {page}")
                    break
                
                page += 1
                time.sleep(2)  # –ü–∞—É–∑–∞ –º–µ–∂–¥—É —Å—Ç—Ä–∞–Ω–∏—Ü–∞–º–∏
            
            print(f"\n –°–æ–±—Ä–∞–Ω–æ –Ω–æ–≤–æ—Å—Ç–µ–π: {len(self.news_data)}")
            
            print(f"\nüìñ –≠–¢–ê–ü 2: –ü–æ–ª—É—á–µ–Ω–∏–µ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏—è –Ω–æ–≤–æ—Å—Ç–µ–π")
            print("-" * 50)
            
            successful_extractions = 0
            failed_extractions = 0
            
            for i, news_item in enumerate(self.news_data, 1):
                print(f"[{i}/{len(self.news_data)}] ", end="")
                
                try:
                    success = self.extract_news_content(news_item)
                    if success and news_item['content_extracted']:
                        successful_extractions += 1
                    else:
                        failed_extractions += 1
                        
                    time.sleep(1)
                    
                except Exception as e:
                    print(f" –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –Ω–æ–≤–æ—Å—Ç–∏ {i}: {e}")
                    failed_extractions += 1
                    continue
            
            print(f"\n –°–¢–ê–¢–ò–°–¢–ò–ö–ê –ò–ó–í–õ–ï–ß–ï–ù–ò–Ø –°–û–î–ï–†–ñ–ê–ù–ò–Ø:")
            print(f" –£—Å–ø–µ—à–Ω–æ: {successful_extractions}")
            print(f" –û—à–∏–±–∫–∏: {failed_extractions}")
            print(f" –£—Å–ø–µ—à–Ω–æ—Å—Ç—å: {successful_extractions/len(self.news_data)*100:.1f}%")
            
            return True
            
        except Exception as e:
            print(f" –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞: {e}")
            return False
        finally:
            if self.driver:
                self.driver.quit()
    
    def save_data(self, filename_prefix="extended_news"):
        """–°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–∞–Ω–Ω—ã–µ –≤ JSON –∏ CSV"""
        if not self.news_data:
            print(" –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è")
            return
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        json_filename = f"{filename_prefix}_{timestamp}.json"
        with open(json_filename, 'w', encoding='utf-8') as f:
            json.dump(self.news_data, f, ensure_ascii=False, indent=2)
        print(f" –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤ JSON: {json_filename}")
        
        csv_filename = f"{filename_prefix}_{timestamp}.csv"
        if self.news_data:
            with open(csv_filename, 'w', newline='', encoding='utf-8') as f:
                writer = csv.DictWriter(f, fieldnames=self.news_data[0].keys())
                writer.writeheader()
                writer.writerows(self.news_data)
            print(f" –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤ CSV: {csv_filename}")

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    print(" E-disclosure.ru Extended News Parser")
    print("=" * 60)
    
    parser = ExtendedNewsParser(headless=False)  # –ü–æ–∫–∞ –≤–∏–¥–∏–º—ã–π —Ä–µ–∂–∏–º
    
    success = parser.parse_all_news_with_content(max_pages=3)  # –ù–∞—á–Ω–µ–º —Å 3 —Å—Ç—Ä–∞–Ω–∏—Ü
    
    if success:
        parser.save_data()
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        total_news = len(parser.news_data)
        with_content = sum(1 for item in parser.news_data if item['content_extracted'])
        
        print(f"\n –ü–∞—Ä—Å–∏–Ω–≥ —É—Å–ø–µ—à–Ω–æ –∑–∞–≤–µ—Ä—à–µ–Ω!")
        print(f" –í—Å–µ–≥–æ –Ω–æ–≤–æ—Å—Ç–µ–π: {total_news}")
        print(f" –° —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ–º: {with_content}")
        print(f" –ü–æ–ª–Ω–æ—Ç–∞ –¥–∞–Ω–Ω—ã—Ö: {with_content/total_news*100:.1f}%")
    else:
        print(" –ü–∞—Ä—Å–∏–Ω–≥ –Ω–µ —É–¥–∞–ª—Å—è")

if __name__ == "__main__":
    main()