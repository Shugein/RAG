#!/usr/bin/env python3
# scripts/test_topic_classifier_simple.py
"""
–ü—Ä–æ—Å—Ç–æ–π —Ç–µ—Å—Ç TopicClassifier –±–µ–∑ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ –≤–Ω–µ—à–Ω–∏–º —Å–µ—Ä–≤–∏—Å–∞–º
"""

import asyncio
import sys
from pathlib import Path
from datetime import datetime

# –î–æ–±–∞–≤–ª—è–µ–º –∫–æ—Ä–µ–Ω—å –ø—Ä–æ–µ–∫—Ç–∞ –≤ –ø—É—Ç—å
sys.path.insert(0, str(Path(__file__).parent.parent))

from Parser.src.services.enricher.sector_mapper import SectorMapper, SectorTaxonomy
from Parser.src.services.enricher.topic_classifier import ClassificationResult
from Parser.src.graph_models import News, Company, NewsType, NewsSubtype


def test_sector_mapper():
    """–¢–µ—Å—Ç SectorMapper"""
    print("=" * 60)
    print("–¢–ï–°–¢ 1: SectorMapper")
    print("=" * 60)
    
    mapper = SectorMapper(SectorTaxonomy.ICB)
    
    # –¢–µ—Å—Ç –ø–æ —Ç–∏–∫–µ—Ä–∞–º
    test_tickers = ["SBER", "GAZP", "YNDX", "MGNT", "GMKN", "MTSS"]
    
    print("\nüè∑Ô∏è  –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –ø–æ —Ç–∏–∫–µ—Ä–∞–º:")
    for ticker in test_tickers:
        sector = mapper.get_sector_by_ticker(ticker)
        if sector:
            print(f"  {ticker}: {sector.name} (ID: {sector.id}, Level: {sector.level})")
        else:
            print(f"  {ticker}: –ù–µ –Ω–∞–π–¥–µ–Ω–æ")
    
    # –¢–µ—Å—Ç –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º
    test_keywords = [
        ["–±–∞–Ω–∫", "–∫—Ä–µ–¥–∏—Ç", "—Ñ–∏–Ω–∞–Ω—Å—ã"],
        ["–Ω–µ—Ñ—Ç—å", "–≥–∞–∑", "—ç–Ω–µ—Ä–≥–∏—è"],
        ["—Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏", "—Å–æ—Ñ—Ç", "–∏–Ω—Ç–µ—Ä–Ω–µ—Ç"],
        ["—Ä–∏—Ç–µ–π–ª", "—Ç–æ—Ä–≥–æ–≤–ª—è", "–º–∞–≥–∞–∑–∏–Ω"],
        ["–º–µ—Ç–∞–ª–ª—ã", "–¥–æ–±—ã—á–∞", "—à–∞—Ö—Ç–∞"]
    ]
    
    print("\nüîç –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º:")
    for keywords in test_keywords:
        sector = mapper.get_sector_by_keywords(keywords)
        if sector:
            print(f"  {keywords}: {sector.name} (ID: {sector.id})")
        else:
            print(f"  {keywords}: –ù–µ –Ω–∞–π–¥–µ–Ω–æ")
    
    # –¢–µ—Å—Ç –∏–µ—Ä–∞—Ä—Ö–∏–∏
    print("\nüå≥ –ò–µ—Ä–∞—Ä—Ö–∏—è –±–∞–Ω–∫–æ–≤—Å–∫–æ–≥–æ —Å–µ–∫—Ç–æ—Ä–∞:")
    hierarchy = mapper.get_sector_hierarchy("9010")
    for parent in hierarchy["parents"]:
        print(f"  –†–æ–¥–∏—Ç–µ–ª—å: {parent.name}")
    print(f"  –¢–µ–∫—É—â–∏–π: {hierarchy['current'][0].name}")
    for child in hierarchy["children"]:
        print(f"  –î–æ—á–µ—Ä–Ω–∏–π: {child.name}")


def test_classification_result():
    """–¢–µ—Å—Ç ClassificationResult"""
    print("\n" + "=" * 60)
    print("–¢–ï–°–¢ 2: ClassificationResult")
    print("=" * 60)
    
    # –°–æ–∑–¥–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏
    result = ClassificationResult(
        primary_sector="9010",
        secondary_sector="9020",
        sector_confidence=0.85,
        primary_country="RU",
        countries_mentioned=["RU", "US"],
        news_type=NewsType.ONE_COMPANY,
        news_subtype=NewsSubtype.EARNINGS,
        type_confidence=0.9,
        tags=["dividends", "quarterly"],
        is_market_wide=False,
        is_regulatory=False,
        is_earnings=True
    )
    
    print("\nüìä –†–µ–∑—É–ª—å—Ç–∞—Ç –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏:")
    print(f"  –û—Å–Ω–æ–≤–Ω–æ–π —Å–µ–∫—Ç–æ—Ä: {result.primary_sector}")
    print(f"  –í—Ç–æ—Ä–∏—á–Ω—ã–π —Å–µ–∫—Ç–æ—Ä: {result.secondary_sector}")
    print(f"  –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –≤ —Å–µ–∫—Ç–æ—Ä–µ: {result.sector_confidence}")
    print(f"  –û—Å–Ω–æ–≤–Ω–∞—è —Å—Ç—Ä–∞–Ω–∞: {result.primary_country}")
    print(f"  –£–ø–æ–º–∏–Ω–∞–µ–º—ã–µ —Å—Ç—Ä–∞–Ω—ã: {result.countries_mentioned}")
    print(f"  –¢–∏–ø –Ω–æ–≤–æ—Å—Ç–∏: {result.news_type}")
    print(f"  –ü–æ–¥—Ç–∏–ø: {result.news_subtype}")
    print(f"  –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –≤ —Ç–∏–ø–µ: {result.type_confidence}")
    print(f"  –¢–µ–≥–∏: {result.tags}")
    print(f"  –†—ã–Ω–æ—á–Ω–∞—è –Ω–æ–≤–æ—Å—Ç—å: {result.is_market_wide}")
    print(f"  –†–µ–≥—É–ª—è—Ç–æ—Ä–Ω–∞—è: {result.is_regulatory}")
    print(f"  –û—Ç—á–µ—Ç–Ω–æ—Å—Ç—å: {result.is_earnings}")


def test_news_models():
    """–¢–µ—Å—Ç –º–æ–¥–µ–ª–µ–π –Ω–æ–≤–æ—Å—Ç–µ–π"""
    print("\n" + "=" * 60)
    print("–¢–ï–°–¢ 3: –ú–æ–¥–µ–ª–∏ –Ω–æ–≤–æ—Å—Ç–µ–π")
    print("=" * 60)
    
    # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤–æ—Å—Ç—å
    news = News(
        id="test_news_1",
        url="https://example.com/news1",
        title="–°–±–µ—Ä–±–∞–Ω–∫ –æ—Ç—á–∏—Ç–∞–ª—Å—è –æ —Ä–µ–∫–æ—Ä–¥–Ω–æ–π –ø—Ä–∏–±—ã–ª–∏ –≤ —Ç—Ä–µ—Ç—å–µ–º –∫–≤–∞—Ä—Ç–∞–ª–µ",
        text="–ü–ê–û –°–±–µ—Ä–±–∞–Ω–∫ –æ–±—ä—è–≤–∏–ª –æ —Ä–æ—Å—Ç–µ —á–∏—Å—Ç–æ–π –ø—Ä–∏–±—ã–ª–∏ –Ω–∞ 25% –≤ —Ç—Ä–µ—Ç—å–µ–º –∫–≤–∞—Ä—Ç–∞–ª–µ 2024 –≥–æ–¥–∞. –í—ã—Ä—É—á–∫–∞ –±–∞–Ω–∫–∞ —Å–æ—Å—Ç–∞–≤–∏–ª–∞ 1.2 —Ç—Ä–ª–Ω —Ä—É–±–ª–µ–π.",
        lang_orig="ru",
        lang_norm="ru",
        published_at=datetime.utcnow(),
        source="test"
    )
    
    print("\nüì∞ –ù–æ–≤–æ—Å—Ç—å:")
    print(f"  ID: {news.id}")
    print(f"  –ó–∞–≥–æ–ª–æ–≤–æ–∫: {news.title}")
    print(f"  –Ø–∑—ã–∫: {news.lang_norm}")
    print(f"  –ò—Å—Ç–æ—á–Ω–∏–∫: {news.source}")
    print(f"  –û–ø—É–±–ª–∏–∫–æ–≤–∞–Ω–∞: {news.published_at}")
    
    # –°–æ–∑–¥–∞–µ–º –∫–æ–º–ø–∞–Ω–∏—é
    company = Company(
        id="sber",
        name="–ü–ê–û –°–±–µ—Ä–±–∞–Ω–∫",
        ticker="SBER",
        country_code="RU"
    )
    
    print("\nüè¢ –ö–æ–º–ø–∞–Ω–∏—è:")
    print(f"  ID: {company.id}")
    print(f"  –ù–∞–∑–≤–∞–Ω–∏–µ: {company.name}")
    print(f"  –¢–∏–∫–µ—Ä: {company.ticker}")
    print(f"  –°—Ç—Ä–∞–Ω–∞: {company.country_code}")


def test_sector_classification():
    """–¢–µ—Å—Ç –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ —Å–µ–∫—Ç–æ—Ä–æ–≤"""
    print("\n" + "=" * 60)
    print("–¢–ï–°–¢ 4: –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è —Å–µ–∫—Ç–æ—Ä–æ–≤")
    print("=" * 60)
    
    mapper = SectorMapper(SectorTaxonomy.ICB)
    
    # –¢–µ—Å—Ç–æ–≤—ã–µ –∫–æ–º–ø–∞–Ω–∏–∏
    companies = [
        Company(id="sber", name="–ü–ê–û –°–±–µ—Ä–±–∞–Ω–∫", ticker="SBER", country_code="RU"),
        Company(id="gazp", name="–ü–ê–û –ì–∞–∑–ø—Ä–æ–º", ticker="GAZP", country_code="RU"),
        Company(id="yndx", name="–Ø–Ω–¥–µ–∫—Å –ù–í", ticker="YNDX", country_code="RU"),
        Company(id="mgnt", name="–ü–ê–û –ú–∞–≥–Ω–∏—Ç", ticker="MGNT", country_code="RU"),
    ]
    
    print("\nüè≠ –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –∫–æ–º–ø–∞–Ω–∏–π –ø–æ —Å–µ–∫—Ç–æ—Ä–∞–º:")
    for company in companies:
        sector = mapper.get_sector_by_ticker(company.ticker)
        if sector:
            print(f"  {company.name} ({company.ticker}): {sector.name} (ID: {sector.id})")
        else:
            print(f"  {company.name} ({company.ticker}): –ù–µ –Ω–∞–π–¥–µ–Ω–æ")


def test_country_extraction():
    """–¢–µ—Å—Ç –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Å—Ç—Ä–∞–Ω"""
    print("\n" + "=" * 60)
    print("–¢–ï–°–¢ 5: –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Å—Ç—Ä–∞–Ω")
    print("=" * 60)
    
    # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º TopicClassifier –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –º–µ—Ç–æ–¥–æ–≤
    from Parser.src.services.enricher.topic_classifier import TopicClassifier
    
    classifier = TopicClassifier()
    
    test_texts = [
        "–†–æ—Å—Å–∏–π—Å–∫–∏–µ –∫–æ–º–ø–∞–Ω–∏–∏ –ø–æ–¥ —Å–∞–Ω–∫—Ü–∏—è–º–∏ –°–®–ê",
        "–ï–≤—Ä–æ–ø–µ–π—Å–∫–∏–µ —Ä—ã–Ω–∫–∏ —É–ø–∞–ª–∏ –Ω–∞ —Ñ–æ–Ω–µ –Ω–æ–≤–æ—Å—Ç–µ–π –∏–∑ –ì–µ—Ä–º–∞–Ω–∏–∏", 
        "–Ø–ø–æ–Ω—Å–∫–∏–µ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏ –≤ –†–æ—Å—Å–∏–∏",
        "–ö–∏—Ç–∞–π –ø–æ–¥–¥–µ—Ä–∂–∞–ª –†–æ—Å—Å–∏—é –≤ –≤–æ–ø—Ä–æ—Å–µ —Å–∞–Ω–∫—Ü–∏–π"
    ]
    
    print("\nüåç –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Å—Ç—Ä–∞–Ω –∏–∑ —Ç–µ–∫—Å—Ç–æ–≤:")
    for i, text in enumerate(test_texts, 1):
        print(f"\n  –¢–µ–∫—Å—Ç {i}: {text}")
        countries = asyncio.run(classifier._extract_countries_from_text(text))
        print(f"    –ù–∞–π–¥–µ–Ω–æ —Å—Ç—Ä–∞–Ω: {countries}")


def test_news_type_classification():
    """–¢–µ—Å—Ç –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ —Ç–∏–ø–æ–≤ –Ω–æ–≤–æ—Å—Ç–µ–π"""
    print("\n" + "=" * 60)
    print("–¢–ï–°–¢ 6: –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è —Ç–∏–ø–æ–≤ –Ω–æ–≤–æ—Å—Ç–µ–π")
    print("=" * 60)
    
    from Parser.src.services.enricher.topic_classifier import TopicClassifier
    
    classifier = TopicClassifier()
    
    test_cases = [
        {
            "title": "–°–±–µ—Ä–±–∞–Ω–∫ –æ–±—ä—è–≤–∏–ª –æ –≤—ã–ø–ª–∞—Ç–µ –¥–∏–≤–∏–¥–µ–Ω–¥–æ–≤",
            "text": "–ü–ê–û –°–±–µ—Ä–±–∞–Ω–∫ –ø—Ä–∏–Ω—è–ª —Ä–µ—à–µ–Ω–∏–µ –æ –≤—ã–ø–ª–∞—Ç–µ –¥–∏–≤–∏–¥–µ–Ω–¥–æ–≤ –≤ —Ä–∞–∑–º–µ—Ä–µ 25 —Ä—É–±–ª–µ–π –Ω–∞ –∞–∫—Ü–∏—é.",
            "expected_type": NewsType.ONE_COMPANY,
            "expected_subtype": NewsSubtype.EARNINGS
        },
        {
            "title": "–¶–ë –†–§ –ø–æ–≤—ã—Å–∏–ª –∫–ª—é—á–µ–≤—É—é —Å—Ç–∞–≤–∫—É",
            "text": "–ë–∞–Ω–∫ –†–æ—Å—Å–∏–∏ –ø–æ–≤—ã—Å–∏–ª –∫–ª—é—á–µ–≤—É—é —Å—Ç–∞–≤–∫—É –Ω–∞ 1 –ø—Ä–æ—Ü–µ–Ω—Ç–Ω—ã–π –ø—É–Ω–∫—Ç –¥–æ 16%.",
            "expected_type": NewsType.REGULATORY,
            "expected_subtype": None
        },
        {
            "title": "–ú–æ—Å–∫–æ–≤—Å–∫–∞—è –±–∏—Ä–∂–∞ –∑–∞–∫—Ä—ã–ª–∞—Å—å –≤ –ø–ª—é—Å–µ",
            "text": "–ò–Ω–¥–µ–∫—Å –ú–æ—Å–ë–∏—Ä–∂–∏ –≤—ã—Ä–æ—Å –Ω–∞ 2.5% –Ω–∞ —Ñ–æ–Ω–µ –ø–æ–∑–∏—Ç–∏–≤–Ω—ã—Ö –Ω–æ–≤–æ—Å—Ç–µ–π.",
            "expected_type": NewsType.MARKET,
            "expected_subtype": None
        },
        {
            "title": "–•–∞–∫–µ—Ä—ã –∞—Ç–∞–∫–æ–≤–∞–ª–∏ –±–∞–Ω–∫–æ–≤—Å–∫–∏–µ —Å–∏—Å—Ç–µ–º—ã",
            "text": "–ö–∏–±–µ—Ä–∞—Ç–∞–∫–∞ –Ω–∞ —Ä–æ—Å—Å–∏–π—Å–∫–∏–µ –±–∞–Ω–∫–∏ –ø—Ä–∏–≤–µ–ª–∞ –∫ –≤—Ä–µ–º–µ–Ω–Ω–æ–º—É –æ—Ç–∫–ª—é—á–µ–Ω–∏—é —Å–µ—Ä–≤–∏—Å–æ–≤.",
            "expected_type": NewsType.REGULATORY,
            "expected_subtype": NewsSubtype.HACK
        }
    ]
    
    print("\nüì∞ –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è —Ç–∏–ø–æ–≤ –Ω–æ–≤–æ—Å—Ç–µ–π:")
    for i, case in enumerate(test_cases, 1):
        print(f"\n  –¢–µ—Å—Ç {i}: {case['title']}")
        
        news = News(
            id=f"type_test_{i}",
            url=f"https://example.com/type{i}",
            title=case["title"],
            text=case["text"],
            lang_orig="ru",
            lang_norm="ru",
            published_at=datetime.utcnow(),
            source="test"
        )
        
        # –¢–µ—Å—Ç–∏—Ä—É–µ–º —Ç–æ–ª—å–∫–æ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—é —Ç–∏–ø–∞ (–±–µ–∑ –≥—Ä–∞—Ñ–∞)
        result = ClassificationResult()
        asyncio.run(classifier._classify_news_type(result, news, []))
        
        print(f"    –¢–∏–ø: {result.news_type} (–æ–∂–∏–¥–∞–ª—Å—è: {case['expected_type']})")
        print(f"    –ü–æ–¥—Ç–∏–ø: {result.news_subtype} (–æ–∂–∏–¥–∞–ª—Å—è: {case['expected_subtype']})")
        print(f"    –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {result.type_confidence:.2f}")
        print(f"    –†—ã–Ω–æ—á–Ω–∞—è: {result.is_market_wide}")
        print(f"    –†–µ–≥—É–ª—è—Ç–æ—Ä–Ω–∞—è: {result.is_regulatory}")


def main():
    """–ó–∞–ø—É—Å–∫ –≤—Å–µ—Ö —Ç–µ—Å—Ç–æ–≤"""
    print("\n" + "üöÄ" * 30)
    print("–ü–†–û–°–¢–û–ï –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï TOPIC CLASSIFIER")
    print("üöÄ" * 30)
    
    try:
        # –ó–∞–ø—É—Å–∫–∞–µ–º —Ç–µ—Å—Ç—ã –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ
        test_sector_mapper()
        test_classification_result()
        test_news_models()
        test_sector_classification()
        test_country_extraction()
        test_news_type_classification()
        
        print("\n" + "=" * 60)
        print("‚úÖ –í–°–ï –¢–ï–°–¢–´ –ó–ê–í–ï–†–®–ï–ù–´ –£–°–ü–ï–®–ù–û")
        print("=" * 60)
        
        print("\nüìù –†–µ–∑—É–ª—å—Ç–∞—Ç—ã:")
        print("  ‚úÖ SectorMapper —Ä–∞–±–æ—Ç–∞–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ")
        print("  ‚úÖ ClassificationResult —Å–æ–∑–¥–∞–µ—Ç—Å—è –ø—Ä–∞–≤–∏–ª—å–Ω–æ")
        print("  ‚úÖ –ú–æ–¥–µ–ª–∏ News –∏ Company —Ä–∞–±–æ—Ç–∞—é—Ç")
        print("  ‚úÖ –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è —Å–µ–∫—Ç–æ—Ä–æ–≤ –ø–æ —Ç–∏–∫–µ—Ä–∞–º")
        print("  ‚úÖ –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Å—Ç—Ä–∞–Ω –∏–∑ —Ç–µ–∫—Å—Ç–∞")
        print("  ‚úÖ –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è —Ç–∏–ø–æ–≤ –Ω–æ–≤–æ—Å—Ç–µ–π")
        
        print("\nüéØ TopicClassifier –≥–æ—Ç–æ–≤ –∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é!")
        print("   (–î–ª—è –ø–æ–ª–Ω–æ–≥–æ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è —Å –≥—Ä–∞—Ñ–æ–º –Ω—É–∂–µ–Ω Neo4j)")
        
    except KeyboardInterrupt:
        print("\n\n‚ö†Ô∏è  –¢–µ—Å—Ç—ã –ø—Ä–µ—Ä–≤–∞–Ω—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
    except Exception as e:
        print(f"\n\n‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–∏: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()
