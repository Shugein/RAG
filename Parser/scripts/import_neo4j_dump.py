#!/usr/bin/env python3
# scripts/import_neo4j_dump.py
"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è –¥–∞–º–ø–∞ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö Neo4j
–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ –∏–∑:
1. Cypher —Å–∫—Ä–∏–ø—Ç–∞ (.cypher)
2. JSON —Ñ–∞–π–ª–∞ (.json)
3. CSV —Ñ–∞–π–ª–æ–≤ (nodes_*.csv, relationships_*.csv)
"""

import asyncio
import sys
import json
import csv
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Any, Optional

# –î–æ–±–∞–≤–ª—è–µ–º –∫–æ—Ä–µ–Ω—å –ø—Ä–æ–µ–∫—Ç–∞ –≤ –ø—É—Ç—å
sys.path.insert(0, str(Path(__file__).parent.parent))

from Parser.src.core.config import settings
from Parser.src.graph_models import GraphService


class Neo4jDumpImporter:
    """–ö–ª–∞—Å—Å –¥–ª—è –∏–º–ø–æ—Ä—Ç–∞ –¥–∞–Ω–Ω—ã—Ö –≤ Neo4j –∏–∑ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —Ñ–æ—Ä–º–∞—Ç–æ–≤"""
    
    def __init__(self, graph_service: GraphService):
        self.graph = graph_service
    
    async def import_cypher_dump(self, cypher_file: str) -> None:
        """–ò–º–ø–æ—Ä—Ç –∏–∑ Cypher —Å–∫—Ä–∏–ø—Ç–∞"""
        print(f"üìù –ò–º–ø–æ—Ä—Ç –∏–∑ Cypher —Ñ–∞–π–ª–∞: {cypher_file}")
        
        if not Path(cypher_file).exists():
            raise FileNotFoundError(f"–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {cypher_file}")
        
        with open(cypher_file, 'r', encoding='utf-8') as f:
            cypher_script = f.read()
        
        # –†–∞–∑–±–∏–≤–∞–µ–º —Å–∫—Ä–∏–ø—Ç –Ω–∞ –æ—Ç–¥–µ–ª—å–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã
        statements = [stmt.strip() for stmt in cypher_script.split(';') if stmt.strip()]
        
        async with self.graph.driver.session() as session:
            for i, statement in enumerate(statements, 1):
                if statement.startswith('--'):
                    continue  # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏
                
                try:
                    print(f"  –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –∑–∞–ø—Ä–æ—Å–∞ {i}/{len(statements)}...")
                    await session.run(statement)
                except Exception as e:
                    print(f"  ‚ö†Ô∏è  –û—à–∏–±–∫–∞ –≤ –∑–∞–ø—Ä–æ—Å–µ {i}: {e}")
                    print(f"  –ó–∞–ø—Ä–æ—Å: {statement[:100]}...")
                    # –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –æ—Å—Ç–∞–ª—å–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
        
        print(f"‚úÖ Cypher –¥–∞–º–ø –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω: {cypher_file}")
    
    async def import_json_dump(self, json_file: str) -> None:
        """–ò–º–ø–æ—Ä—Ç –∏–∑ JSON —Ñ–∞–π–ª–∞"""
        print(f"üìÑ –ò–º–ø–æ—Ä—Ç –∏–∑ JSON —Ñ–∞–π–ª–∞: {json_file}")
        
        if not Path(json_file).exists():
            raise FileNotFoundError(f"–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {json_file}")
        
        with open(json_file, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        async with self.graph.driver.session() as session:
            # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º —É–∑–ª—ã
            print(f"  –ò–º–ø–æ—Ä—Ç {len(data['nodes'])} —É–∑–ª–æ–≤...")
            for node_data in data['nodes']:
                labels = ':'.join(node_data['labels'])
                properties = node_data['properties']
                
                # –°–æ–∑–¥–∞–µ–º —É–∑–µ–ª
                prop_str = ', '.join([f"{k}: ${k}" for k in properties.keys()])
                query = f"CREATE (n:{labels} {{{prop_str}}})"
                
                await session.run(query, properties)
            
            # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º —Å–≤—è–∑–∏
            print(f"  –ò–º–ø–æ—Ä—Ç {len(data['relationships'])} —Å–≤—è–∑–µ–π...")
            for rel_data in data['relationships']:
                rel_type = rel_data['type']
                start_id = rel_data['start_node']
                end_id = rel_data['end_node']
                properties = rel_data['properties']
                
                # –°–æ–∑–¥–∞–µ–º —Å–≤—è–∑—å
                prop_str = ', '.join([f"{k}: ${k}" for k in properties.keys()]) if properties else ""
                if prop_str:
                    query = f"""
                        MATCH (a), (b)
                        WHERE a.element_id = $start_id AND b.element_id = $end_id
                        CREATE (a)-[r:{rel_type} {{{prop_str}}}]->(b)
                    """
                    params = {"start_id": start_id, "end_id": end_id, **properties}
                else:
                    query = f"""
                        MATCH (a), (b)
                        WHERE a.element_id = $start_id AND b.element_id = $end_id
                        CREATE (a)-[r:{rel_type}]->(b)
                    """
                    params = {"start_id": start_id, "end_id": end_id}
                
                await session.run(query, params)
        
        print(f"‚úÖ JSON –¥–∞–º–ø –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω: {json_file}")
    
    async def import_csv_dump(self, csv_dir: str) -> None:
        """–ò–º–ø–æ—Ä—Ç –∏–∑ CSV —Ñ–∞–π–ª–æ–≤"""
        print(f"üìä –ò–º–ø–æ—Ä—Ç –∏–∑ CSV –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏: {csv_dir}")
        
        csv_path = Path(csv_dir)
        if not csv_path.exists():
            raise FileNotFoundError(f"–î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {csv_dir}")
        
        # –ù–∞—Ö–æ–¥–∏–º —Ñ–∞–π–ª—ã —É–∑–ª–æ–≤ –∏ —Å–≤—è–∑–µ–π
        nodes_files = list(csv_path.glob("nodes_*.csv"))
        rels_files = list(csv_path.glob("relationships_*.csv"))
        
        if not nodes_files:
            raise FileNotFoundError("–ù–µ –Ω–∞–π–¥–µ–Ω—ã —Ñ–∞–π–ª—ã —É–∑–ª–æ–≤ (nodes_*.csv)")
        
        async with self.graph.driver.session() as session:
            # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º —É–∑–ª—ã
            for nodes_file in nodes_files:
                print(f"  –ò–º–ø–æ—Ä—Ç —É–∑–ª–æ–≤ –∏–∑: {nodes_file.name}")
                
                with open(nodes_file, 'r', encoding='utf-8') as f:
                    reader = csv.DictReader(f)
                    
                    for row in reader:
                        labels = row['labels'].split('|')
                        labels_str = ':'.join(labels)
                        
                        # –£–±–∏—Ä–∞–µ–º —Å–ª—É–∂–µ–±–Ω—ã–µ –ø–æ–ª—è
                        properties = {k: v for k, v in row.items() if k not in ['id', 'labels']}
                        
                        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –∑–Ω–∞—á–µ–Ω–∏—è
                        for key, value in properties.items():
                            if value == '':
                                properties[key] = None
                            elif value.lower() in ['true', 'false']:
                                properties[key] = value.lower() == 'true'
                            elif value.isdigit():
                                properties[key] = int(value)
                            elif value.replace('.', '').isdigit():
                                properties[key] = float(value)
                        
                        # –°–æ–∑–¥–∞–µ–º —É–∑–µ–ª
                        prop_str = ', '.join([f"{k}: ${k}" for k in properties.keys()])
                        query = f"CREATE (n:{labels_str} {{{prop_str}}})"
                        
                        await session.run(query, properties)
            
            # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º —Å–≤—è–∑–∏
            for rels_file in rels_files:
                print(f"  –ò–º–ø–æ—Ä—Ç —Å–≤—è–∑–µ–π –∏–∑: {rels_file.name}")
                
                with open(rels_file, 'r', encoding='utf-8') as f:
                    reader = csv.DictReader(f)
                    
                    for row in reader:
                        rel_type = row['type']
                        start_id = row['start_node']
                        end_id = row['end_node']
                        
                        # –£–±–∏—Ä–∞–µ–º —Å–ª—É–∂–µ–±–Ω—ã–µ –ø–æ–ª—è
                        properties = {k: v for k, v in row.items() if k not in ['id', 'type', 'start_node', 'end_node']}
                        
                        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –∑–Ω–∞—á–µ–Ω–∏—è
                        for key, value in properties.items():
                            if value == '':
                                properties[key] = None
                            elif value.lower() in ['true', 'false']:
                                properties[key] = value.lower() == 'true'
                            elif value.isdigit():
                                properties[key] = int(value)
                            elif value.replace('.', '').isdigit():
                                properties[key] = float(value)
                        
                        # –°–æ–∑–¥–∞–µ–º —Å–≤—è–∑—å
                        prop_str = ', '.join([f"{k}: ${k}" for k in properties.keys()]) if properties else ""
                        if prop_str:
                            query = f"""
                                MATCH (a), (b)
                                WHERE a.element_id = $start_id AND b.element_id = $end_id
                                CREATE (a)-[r:{rel_type} {{{prop_str}}}]->(b)
                            """
                            params = {"start_id": start_id, "end_id": end_id, **properties}
                        else:
                            query = f"""
                                MATCH (a), (b)
                                WHERE a.element_id = $start_id AND b.element_id = $end_id
                                CREATE (a)-[r:{rel_type}]->(b)
                            """
                            params = {"start_id": start_id, "end_id": end_id}
                        
                        await session.run(query, params)
        
        print(f"‚úÖ CSV –¥–∞–º–ø –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω: {csv_dir}")
    
    async def clear_database(self) -> None:
        """–û—á–∏—Å—Ç–∫–∞ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö –ø–µ—Ä–µ–¥ –∏–º–ø–æ—Ä—Ç–æ–º"""
        print("üóëÔ∏è  –û—á–∏—Å—Ç–∫–∞ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö...")
        
        async with self.graph.driver.session() as session:
            # –£–¥–∞–ª—è–µ–º –≤—Å–µ —Å–≤—è–∑–∏ –∏ —É–∑–ª—ã
            await session.run("MATCH (n) DETACH DELETE n")
        
        print("‚úÖ –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö –æ—á–∏—â–µ–Ω–∞")
    
    async def verify_import(self) -> None:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ —É—Å–ø–µ—à–Ω–æ—Å—Ç–∏ –∏–º–ø–æ—Ä—Ç–∞"""
        print("üîç –ü—Ä–æ–≤–µ—Ä–∫–∞ –∏–º–ø–æ—Ä—Ç–∞...")
        
        async with self.graph.driver.session() as session:
            # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º —É–∑–ª—ã –ø–æ —Ç–∏–ø–∞–º
            result = await session.run("MATCH (n) RETURN labels(n) as labels, count(n) as count")
            print("  –£–∑–ª—ã –ø–æ —Ç–∏–ø–∞–º:")
            async for record in result:
                labels = record['labels']
                count = record['count']
                print(f"    {':'.join(labels)}: {count}")
            
            # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º —Å–≤—è–∑–∏ –ø–æ —Ç–∏–ø–∞–º
            result = await session.run("MATCH ()-[r]->() RETURN type(r) as type, count(r) as count")
            print("  –°–≤—è–∑–∏ –ø–æ —Ç–∏–ø–∞–º:")
            async for record in result:
                rel_type = record['type']
                count = record['count']
                print(f"    {rel_type}: {count}")
        
        print("‚úÖ –ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞")


async def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    import argparse
    
    parser = argparse.ArgumentParser(description="–ò–º–ø–æ—Ä—Ç –¥–∞–º–ø–∞ Neo4j")
    parser.add_argument("file", help="–ü—É—Ç—å –∫ —Ñ–∞–π–ª—É –¥–∞–º–ø–∞ –∏–ª–∏ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ —Å CSV —Ñ–∞–π–ª–∞–º–∏")
    parser.add_argument("--clear", action="store_true", help="–û—á–∏—Å—Ç–∏—Ç—å –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö –ø–µ—Ä–µ–¥ –∏–º–ø–æ—Ä—Ç–æ–º")
    parser.add_argument("--verify", action="store_true", help="–ü—Ä–æ–≤–µ—Ä–∏—Ç—å –∏–º–ø–æ—Ä—Ç –ø–æ—Å–ª–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è")
    
    args = parser.parse_args()
    
    print("üöÄ" * 30)
    print("–ò–ú–ü–û–†–¢ –î–ê–ú–ü–ê NEO4J")
    print("üöÄ" * 30)
    
    # –°–æ–∑–¥–∞–µ–º –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ Neo4j
    try:
        graph = GraphService(
            uri=settings.NEO4J_URI,
            user=settings.NEO4J_USER,
            password=settings.NEO4J_PASSWORD
        )
        
        # –¢–µ—Å—Ç–∏—Ä—É–µ–º –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ
        async with graph.driver.session() as session:
            result = await session.run("RETURN 'Connected' as status")
            record = await result.single()
            print(f"‚úÖ –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ Neo4j: {record['status']}")
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ Neo4j: {e}")
        print("\nüí° –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ Neo4j –∑–∞–ø—É—â–µ–Ω:")
        print("   docker-compose up neo4j")
        return
    
    # –°–æ–∑–¥–∞–µ–º –∏–º–ø–æ—Ä—Ç–µ—Ä
    importer = Neo4jDumpImporter(graph)
    
    try:
        # –û—á–∏—â–∞–µ–º –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
        if args.clear:
            await importer.clear_database()
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø —Ñ–∞–π–ª–∞ –∏ –∏–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º
        file_path = Path(args.file)
        
        if file_path.suffix == '.cypher':
            await importer.import_cypher_dump(str(file_path))
        elif file_path.suffix == '.json':
            await importer.import_json_dump(str(file_path))
        elif file_path.is_dir():
            await importer.import_csv_dump(str(file_path))
        else:
            print(f"‚ùå –ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç —Ñ–∞–π–ª–∞: {file_path.suffix}")
            print("üí° –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã: .cypher, .json, –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è —Å CSV —Ñ–∞–π–ª–∞–º–∏")
            return
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏–º–ø–æ—Ä—Ç –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
        if args.verify:
            await importer.verify_import()
        
        print(f"\n‚úÖ –ò–º–ø–æ—Ä—Ç –∑–∞–≤–µ—Ä—à–µ–Ω —É—Å–ø–µ—à–Ω–æ!")
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∏–º–ø–æ—Ä—Ç–∞: {e}")
    
    finally:
        await graph.close()


if __name__ == "__main__":
    asyncio.run(main())
